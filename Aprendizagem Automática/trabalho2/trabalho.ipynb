{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Universidade de Évora<br/>Ano Letivo 2020/2021<br/>Aprendizagem Automática - Trabalho 2 |\n",
    "| ------------ |\n",
    "| Trabalho realizado por:<br/>José Lopes nº 37861<br/>Dinis Matos nº 42738 |\n",
    "\n",
    "Este trabalho tem como objetivo construir um modelo preditivo em relação aos alunos que estão em risco de abandonar o curso. Os dados a serem analisados são todos da universidade, como por exemplo os vários tipos diferentes de cursos em que os alunos estão inscritos, o número de pessoas inscritas nas cadeiras desses cursos e a nota que obtiveram.\n",
    "\n",
    "Foram utilizados 4 tipos diferentes de modelos preditivos: Random Forest, Gradient Tree Boosting, Decision Tree e Weighted Average Probabilities (Soft Voting). O mais bem sucedido foi o Random Forest, que obteve um score de 93% e 95%. De seguida foi a Weighted Average Probabilities (Soft Voting) com 92%, depois foi Gradient Tree Boosting com 91%. Por último o Decision Tree com 90% (ou seja, a ordem dos 5 melhores Setups: 1ª/2ª/5º/3º/4º, de acordo com o código)\n",
    "\n",
    "O \"output\" será criado ou guardado no ficheiro \"result.csv\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# removeDuplicatesFromDict removes duplicates from Dictionary\n",
    "def removeDuplicatesFromDict(dictionary):\n",
    "    aux = [] \n",
    "    new_dict = dict()\n",
    "    for x, y in dictionary.items(): \n",
    "        if y not in aux: \n",
    "            aux.append(y) \n",
    "            new_dict[x] = y\n",
    "    return new_dict\n",
    "\n",
    "# getTrainAndTest returns (x_train, y_train, x_test) from (train.csv & test.csv)\n",
    "def getTrainAndTest():\n",
    "    # Open train\n",
    "    train = pd.read_csv('train.csv')\n",
    "    train = train.astype({\"Program\": \"string\"})\n",
    "\n",
    "    # Get Dictionary (convert Program to number)\n",
    "    dict_program = train.Program.to_dict()\n",
    "    newdict_program = removeDuplicatesFromDict(dict_program)\n",
    "    finaldict_program = {v: k for k, v in newdict_program.items()}\n",
    "\n",
    "    # Change train\n",
    "    train_program = [finaldict_program[x] for x in train.Program]\n",
    "    train.Program = train_program\n",
    "\n",
    "    # Set y_train & x_train\n",
    "    y_train = train.Failure\n",
    "    x_train = train.drop('Failure',axis=1)\n",
    "\n",
    "    # Open x_test\n",
    "    x_test = pd.read_csv('test.csv')\n",
    "    x_test = x_test.astype({\"Program\": \"string\"})\n",
    "\n",
    "    # Change test\n",
    "    x_test_program = [finaldict_program[x] for x in x_test.Program]\n",
    "    x_test.Program = x_test_program\n",
    "    \n",
    "    return x_train, y_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1º Setup: Random Forests (n_estimators=100, max_depth>=20) (0.95833)\n",
    "def getPredict(x_train, y_train, x_test):\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=30, random_state=0)\n",
    "    RF.fit(x_train, y_train)\n",
    "    y_pred = RF.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def main():\n",
    "    \n",
    "    # get x_train, y_train, x_test by getTrainAndTest\n",
    "    x_train, y_train, x_test = getTrainAndTest()\n",
    "    \n",
    "    # get y_pred\n",
    "    y_pred = getPredict(x_train, y_train, x_test)\n",
    "\n",
    "    # Open & Change sampleSubmission\n",
    "    result = pd.DataFrame({'Id': x_test.Id, 'Failure': y_pred})\n",
    "    result.to_csv('result.csv', index = False)\n",
    "    print(\"File result.csv created/changed with the prediction\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2º Setup: Random Forests (n_estimators=100, max_depth=5) (0.93706)\n",
    "def getPredict(x_train, y_train, x_test):\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "    RF.fit(x_train, y_train)\n",
    "    y_pred = RF.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3º Setup: Gradient Tree Boosting (n_estimators=100, max_depth=100, random_state=0) (0.91666)\n",
    "def getPredict(x_train, y_train, x_test):\n",
    "    GBC = GradientBoostingClassifier(n_estimators=100, max_depth=100, random_state=0)\n",
    "    GBC.fit(x_train, y_train)\n",
    "    y_pred = GBC.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4º Setup: Decision Tree (max_depth=20) (0.90410)\n",
    "def getPredict(x_train, y_train, x_test):\n",
    "    DT = DecisionTreeClassifier(max_depth=20)\n",
    "    DT = DT.fit(x_train, y_train)\n",
    "    y_pred = DT.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ª Setup: Weighted Average Probabilities (Soft Voting) (0.92307)\n",
    "def getPredict(x_train, y_train, x_test):\n",
    "    DT = DecisionTreeClassifier(max_depth=20)\n",
    "    KNN = KNeighborsClassifier(n_neighbors=7)\n",
    "    SV = SVC(kernel='rbf', probability=True)\n",
    "    VC = VotingClassifier(estimators=[('dt', DT), ('knn', KNN), ('svc', SV)], voting='soft', weights=[2, 1, 2])\n",
    "    \n",
    "    DT = DT.fit(x_train, y_train)\n",
    "    KNN = KNN.fit(x_train, y_train)\n",
    "    SV = SV.fit(x_train, y_train)\n",
    "    VC = VC.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = VC.predict(x_test)\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
